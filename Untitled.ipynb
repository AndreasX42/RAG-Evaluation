{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3f077f9-cb9d-4b61-b3a9-72bcb2fd57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(), override=True)\n",
    "\n",
    "import numpy as np\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.schema.language_model import BaseLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ed33-74d9-4c63-8533-dc270775d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc0d927-ecba-41fc-8378-35de3fab0d55",
   "metadata": {},
   "source": [
    "# load and split data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e340cdf-f498-4241-84ed-132d4ef93b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resources/msg_life-gb-2021-EN_final.pdf\n"
     ]
    }
   ],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import (\n",
    "        PyPDFLoader, # already splits data during loading\n",
    "        UnstructuredPDFLoader, # returns only 1 Document\n",
    "        PyMuPDFLoader # returns 1 Document per page\n",
    "        )\n",
    "        print(f'Loading {file}')\n",
    "        loader = UnstructuredPDFLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file, encoding=\"utf-8\")\n",
    "    elif extension == \".docx\":\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        loader = Docx2txtLoader(file)\n",
    "\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def split_data(data: List[Document], llm: BaseLanguageModel, chunk_size: Optional[int] = 4096):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \"\"\"\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    enc.encode(x)\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                                   length_function=lambda x: llm.get_num_tokens(x))\n",
    "    \n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "data = load_document(\"resources/msg_life-gb-2021-EN_final.pdf\")\n",
    "chunks = split_data(data, llm=llm, chunk_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e88fc82f-a35b-4e07-aa4a-7c405b269643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in document: 47819\n",
      "number of elements in data: 1\n",
      "number of chunks: 17\n",
      "average number of tokens per chunk: 2812.8823529411766\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of tokens in document: {sum([llm.get_num_tokens(chunk.page_content) for chunk in chunks])}\\\n",
    "\\nnumber of elements in data: {len(data)}\\\n",
    "\\nnumber of chunks: {len(chunks)}\\\n",
    "\\naverage number of tokens per chunk: {np.average([llm.get_num_tokens(chunk.page_content) for chunk in chunks])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3a766-57a2-4b5a-9540-7ebbd37214b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "864a584f-ecab-45be-815a-acc3c515c3f6",
   "metadata": {},
   "source": [
    "# Generate Q/A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e718144d-8fa6-41e3-8fbf-467cf93cc40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not considering 16/17\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"Suppose you are QuestionAnswerGPT, a large language model trained in detecting the most important\n",
    "parts of a document and you are able to come up with a corresponding question and answer pair for these highly important \n",
    "sections in the document, that would help new readers understand the document.\n",
    "\n",
    "Your task is to generate questions and corresponding answers from the given text.\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_MESSAGE = \"\"\"Please generate questions, answers and importance scores in of the following text: {text}\"\"\"\n",
    "\n",
    "CHAT_PROMPT = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(SYSTEM_MESSAGE),\n",
    "        HumanMessagePromptTemplate.from_template(HUMAN_MESSAGE),\n",
    "    ])\n",
    "\n",
    "# generate a Q/A pair for a document chunk\n",
    "def generate_eval_set(llm: BaseLanguageModel, chunks: List[Document]) -> List[Dict[str,str]]:\n",
    "    import numpy as np\n",
    "    from langchain.chains import QAGenerationChain\n",
    "    from json import JSONDecodeError\n",
    "    import itertools\n",
    "\n",
    "    # set up QAGenerationChain chain using GPT 3.5\n",
    "    qa_generator_chain = QAGenerationChain.from_llm(llm)#, prompt=CHAT_PROMPT)\n",
    "    eval_set = []\n",
    "\n",
    "    # catch any QA generation errors and re-try until QA pair is generated\n",
    "    awaiting_answer = True\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        \n",
    "        if llm.get_num_tokens(chunk.page_content) < 1500:\n",
    "            print(f\"Not considering {i}/{len(chunks)}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            qa_pair = qa_generator_chain.run(chunk.page_content)\n",
    "            eval_set.append(qa_pair)\n",
    "            awaiting_answer = False\n",
    "        except JSONDecodeError:\n",
    "            print(f\"Error occurred inside QAChain in chunk {i}/{len(chunks)}\")\n",
    "            \n",
    "    eval_pair = list(itertools.chain.from_iterable(eval_set))\n",
    "    return eval_pair\n",
    "\n",
    "result = generate_eval_set(llm, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ef2a43e-8d2e-4010-8068-e869f6a26cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What were the financial key performance indicators of the msg life Group in the reporting period?\n",
      "-> The msg life Group recorded gross Group revenue from its own business under German GAAP of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) under German GAAP of 17.9 million euros.\n",
      "--------------------------------------------------\n",
      "What is the purpose of msg life's 'life talent' programme?\n",
      "-> The purpose of msg life's 'life talent' programme is to identify employees with potential for strategic and leading roles in the company and provide them with individual support, professional development, and networking opportunities.\n",
      "--------------------------------------------------\n",
      "What rights do shareholders have at the annual general meeting?\n",
      "-> The administrative rights include the right to attend the annual general meeting and speak, ask questions, put forward motions and exercise voting rights.\n",
      "--------------------------------------------------\n",
      "What is the current situation in the insurance market and how is it benefiting msg life?\n",
      "-> The current situation in the insurance market is proving to be an opportunity for msg life, as demonstrated by new contracts over the past few years and current sales projects.\n",
      "--------------------------------------------------\n",
      "What potential risks are associated with the msg life Group's projects?\n",
      "-> The potential risks associated with the msg life Group's projects include exceeding the agreed budget, missing deadlines, failure to comply with functional specifications or required quality, and the need to grant discounts or pay compensation.\n",
      "--------------------------------------------------\n",
      "What are some potential risks mentioned in the text?\n",
      "-> Some potential risks mentioned in the text include recovery expenses, loss of production, recourse claims, economic risks related to the Covid-19 pandemic and the Russian invasion of Ukraine, IT security risks, risks from takeovers, competition risks, and liquidity risks.\n",
      "--------------------------------------------------\n",
      "What is credit risk management responsible for?\n",
      "-> Credit risk management is responsible for the operational measurement and management of credit risks, including monitoring credit risk positions and exposure and analysis of credit ratings.\n",
      "--------------------------------------------------\n",
      "What is the goal of msg life's partnership with IBM?\n",
      "-> The goal is to significantly increase the competitiveness of international insurance companies through a fully digitised end-to-end solution, thereby securing their future.\n",
      "--------------------------------------------------\n",
      "What are some of the regulatory requirements that necessitate changes to the solutions currently used by insurance companies?\n",
      "-> The revision of Solvency II, the new international accounting standard IFRS 17, the European Transparency Directive, the rollout of a digital pension overview, and the introduction of PEPP.\n",
      "--------------------------------------------------\n",
      "What is the significance of the acquisition of closed insurance contract portfolios for larger insurance companies?\n",
      "-> The acquisition of closed insurance contract portfolios allows larger insurance companies to generate positive effects for their books and generate significant economies of scale and cost synergies.\n",
      "--------------------------------------------------\n",
      "What is the purpose of the Supervisory Board?\n",
      "-> The Supervisory Board has the task of examining the consolidated financial statements and declaring whether it approves the consolidated financial statements.\n",
      "--------------------------------------------------\n",
      "How are intangible assets valued?\n",
      "-> Intangible assets acquired for valuable consideration are valued at original cost less depreciation according to the straight-line method, with a useful life of between three and 15 years.\n",
      "--------------------------------------------------\n",
      "How are provisions for pensions and similar obligations measured?\n",
      "-> Provisions for pensions and similar obligations are measured on the basis of actuarial calculations carried out using the projected unit credit method and with consideration for mortality tables.\n",
      "--------------------------------------------------\n",
      "Which companies were fully consolidated in the Group headed by msg life ag as the parent company?\n",
      "-> msg life central europe gmbh, msg life Slovakia s.r.o., msg life Switzerland AG, msg life Austria Ges.m.b.H., msg life Benelux B.V., msg life global gmbh, FJA-US, Inc., msg life odateam d.o.o., msg life Iberia, Unipessoal LDA\n",
      "--------------------------------------------------\n",
      "What are the personnel-related provisions primarily composed of?\n",
      "-> The personnel-related provisions primarily consist of short-term provisions for holidays, overtime, and entitlements to variable remuneration, long-term provisions for anniversary bonuses, and long-term provisions for settlements.\n",
      "--------------------------------------------------\n",
      "What did the auditors conclude about the consolidated financial statements of msg life ag?\n",
      "-> The auditors concluded that the consolidated financial statements comply with the requirements of German commercial law and give a true and fair view of the assets and financial position of the Group.\n",
      "--------------------------------------------------\n",
      "What are some of the tasks that the auditor needs to perform in relation to the consolidated financial statements?\n",
      "-> The auditor needs to obtain an understanding of internal controls, evaluate accounting policies and estimates, conclude on the appropriateness of the going concern basis of accounting, and evaluate the overall presentation of the financial statements.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for qa in result:\n",
    "    if len(qa['answer'])>150:\n",
    "        print(qa[\"question\"])\n",
    "        print(f\"-> {qa['answer']}\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "046b02fb-98aa-41d3-b2c8-6982184d43f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if len(qa[\"answer\"]) > 150 else 0 for qa in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6894e176-039b-42fa-b4a9-740873c4eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dataset = [qa_pair for qa_pair in result if len(qa_pair[\"answer\"]) > 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffded25-d199-494c-9551-aa3cd15ec38b",
   "metadata": {},
   "source": [
    "# Set up vectorstore and retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d8dd9d8-81da-4f78-ba30-06c20de64ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_vs = split_data(data, llm=llm, chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11c0ca75-0ba1-4b9b-b4b8-503a156e320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.vectorstore import VectorStoreRetriever \n",
    "\n",
    "def get_retriever(splits: List[Document], k: int) -> VectorStoreRetriever:\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    from langchain.vectorstores import FAISS\n",
    "    \n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    vectorstore = FAISS.from_documents(splits, embedding_model)\n",
    "    retriever = vectorstore.as_retriever(k=k)\n",
    "        \n",
    "    return retriever\n",
    "\n",
    "retriever = get_retriever(chunks_vs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825656b-89c8-42a6-8fd7-3eb607b9fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025a103f-9c06-4866-ae87-aa8f2ac86058",
   "metadata": {},
   "source": [
    "# LLM chain for query answering based on document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87f0494c-8268-4e9e-9e0b-d2058e65334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from utils import QA_CHAIN_PROMPT\n",
    "\n",
    "def get_qa_llm(llm: BaseLanguageModel, retriever: VectorStoreRetriever) -> RetrievalQA:\n",
    "    \n",
    "    # Select prompt \n",
    "    chain_type_kwargs = {\"prompt\": QA_CHAIN_PROMPT}\n",
    "\n",
    "    qa_llm = RetrievalQA.from_chain_type(llm,\n",
    "                                           chain_type=\"stuff\",\n",
    "                                           retriever=retriever,\n",
    "                                           chain_type_kwargs=chain_type_kwargs,\n",
    "                                           input_key=\"question\"\n",
    "                                          )\n",
    "    return qa_llm\n",
    "\n",
    "qa_llm = get_qa_llm(llm, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30f9a0fb-899c-4a9f-bbbf-ea4d842b9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is TRAIL.X?',\n",
       " 'result': 'TRAIL.X is a project that involves the development of deep neural networks (DNNs) for the actuarial computation module in cooperation with the Ludwig Maximilian University of Munich. These DNNs will enable life insurers to replace old system generations, map their core functions with artificial intelligence, and integrate them into a modern system.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_llm(\"What is TRAIL.X?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7561288-a52e-4d27-be01-882bed8a260f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ac142f-b2a8-4796-ba06-c6d1ff31bf3a",
   "metadata": {},
   "source": [
    "# QA_LLM grading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd32586-82ca-47b2-98f7-18132b533e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a486ab7-611b-4078-90f8-434e08c41a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (GRADE_ANSWER_PROMPT_FAST, \n",
    "                    GRADE_ANSWER_PROMPT_BIAS_CHECK, \n",
    "                    GRADE_ANSWER_PROMPT_OPENAI,\n",
    "                    GRADE_ANSWER_PROMPT)\n",
    "\n",
    "def grade_model_answer(gt_datase: List[Dict[str,str]], \n",
    "                       predictions: List[str],\n",
    "                       grade_answer_prompt: str, \n",
    "                       qa_judge_model: Optional[str] = \"gpt-3.5-turbo\"):\n",
    "\n",
    "    from langchain.evaluation.qa import QAEvalChain    \n",
    "    \n",
    "    if grade_answer_prompt == \"Fast\":\n",
    "        prompt = GRADE_ANSWER_PROMPT_FAST\n",
    "    elif grade_answer_prompt == \"Descriptive w/ bias check\":\n",
    "        prompt = GRADE_ANSWER_PROMPT_BIAS_CHECK\n",
    "    elif grade_answer_prompt == \"OpenAI grading prompt\":\n",
    "        prompt = GRADE_ANSWER_PROMPT_OPENAI\n",
    "    else:\n",
    "        prompt = GRADE_ANSWER_PROMPT\n",
    "\n",
    "    # Note: GPT-4 grader is advised by OAI model_name=\"gpt-4\"\n",
    "    eval_chain = QAEvalChain.from_llm(llm=ChatOpenAI(model_name=qa_judge_model, temperature=0),\n",
    "                                      prompt=prompt, \n",
    "                                      verbose=True)\n",
    "    \n",
    "    graded_outputs = eval_chain.evaluate(gt_datase,\n",
    "                                         predictions,\n",
    "                                         question_key=\"question\",\n",
    "                                         prediction_key=\"result\")\n",
    "    return graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76dcbf2-0eed-4a82-a444-088da48e458e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54ff8d04-8b20-4878-9138-a30362f837d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What were the financial key performance indicators of the msg life Group in the reporting period?',\n",
       " 'answer': 'The msg life Group recorded gross Group revenue from its own business under German GAAP of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) under German GAAP of 17.9 million euros.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04e3cb4e-09e3-4edc-b847-3e9685b8dbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What were the financial key performance indicators of the msg life Group in the reporting period?',\n",
       " 'result': 'In the reporting period, the msg life Group recorded gross Group revenue of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) of 17.9 million euros.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_llm_answer = qa_llm(gt_dataset[0][\"question\"])\n",
    "qa_llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51d8646e-d3cc-4f80-bd03-f08c56cf899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new QAEvalChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a teacher grading a quiz. \n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either Correct or Incorrect.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: Correct or Incorrect here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. If the student answers that there is no specific information provided in the context, then the answer is Incorrect. Begin! \n",
      "\n",
      "QUESTION: What were the financial key performance indicators of the msg life Group in the reporting period?\n",
      "STUDENT ANSWER: In the reporting period, the msg life Group recorded gross Group revenue of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) of 17.9 million euros.\n",
      "TRUE ANSWER: The msg life Group recorded gross Group revenue from its own business under German GAAP of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) under German GAAP of 17.9 million euros.\n",
      "GRADE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'results': 'Correct'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_model_answer([gt_dataset[0]],\n",
    "                   [qa_llm_answer],\n",
    "                   grade_answer_prompt=\"Fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87f95c-8a9c-4295-ada4-44f358d1d52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbcd5f08-5a4d-440d-aef6-1c6d0f70a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for incorrect answer\n",
    "qa_predicted = qa_llm(\"What is TRAIL.X?\")\n",
    "qa_predicted[\"question\"] = gt_dataset[0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3dd31d69-bad6-42ec-8a1f-ba6ee48732b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new QAEvalChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a teacher grading a quiz. \n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either Correct or Incorrect.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: Correct or Incorrect here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. If the student answers that there is no specific information provided in the context, then the answer is Incorrect. Begin! \n",
      "\n",
      "QUESTION: What were the financial key performance indicators of the msg life Group in the reporting period?\n",
      "STUDENT ANSWER: TRAIL.X is a project developed by msg life in cooperation with the Ludwig Maximilian University of Munich. It involves the development of deep neural networks (DNNs) for the actuarial computation module. These DNNs will enable life insurers to replace old system generations and integrate artificial intelligence into their core functions.\n",
      "TRUE ANSWER: The msg life Group recorded gross Group revenue from its own business under German GAAP of 176.1 million euros and Group earnings before interest, taxes, depreciation and amortisation (EBITDA) under German GAAP of 17.9 million euros.\n",
      "GRADE:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'results': 'Incorrect'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_model_answer([gt_dataset[0]],\n",
    "                   [qa_predicted],\n",
    "                   grade_answer_prompt=\"Fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1987b3-5e8b-4eac-bec8-7bcb172488e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c49587-2986-4019-9f26-54381e938604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd721d2-dbd3-427a-8319-e1d3661bcab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0d2f4-671b-4fcd-8cef-0fc0c71a5af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aae50c-0558-4d5d-9c40-9ddb21a7720b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17574664-408f-461e-bfc4-300a0ff1385a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107013b-10d9-47c8-903f-e77ff8a5255f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
